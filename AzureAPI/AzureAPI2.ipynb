{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import requests\n",
    "import cv2\n",
    "import operator\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from config import api_key\n",
    "\n",
    "# Import library to display results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# Display images within Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variables\n",
    "_region = 'westus' #Here you enter the region of your subscription\n",
    "_url = 'https://{}.api.cognitive.microsoft.com/vision/v2.0/analyze'.format(_region)\n",
    "_key = api_key\n",
    "_maxNumRetries = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRequest( json, data, headers, params ):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper function to process the request to Project Oxford\n",
    "\n",
    "    Parameters:\n",
    "    json: Used when processing images from its URL. See API Documentation\n",
    "    data: Used when processing image read from disk. See API Documentation\n",
    "    headers: Used to pass the key information and the data type request\n",
    "    \"\"\"\n",
    "\n",
    "    retries = 0\n",
    "    result = None\n",
    "\n",
    "    while True:\n",
    "\n",
    "        response = requests.request( 'post', _url, json = json, data = data, headers = headers, params = params )\n",
    "\n",
    "        if response.status_code == 429: \n",
    "\n",
    "            print( \"Message: %s\" % ( response.json() ) )\n",
    "\n",
    "            if retries <= _maxNumRetries: \n",
    "                time.sleep(1) \n",
    "                retries += 1\n",
    "                continue\n",
    "            else: \n",
    "                print( 'Error: failed after retrying!' )\n",
    "                break\n",
    "\n",
    "        elif response.status_code == 200 or response.status_code == 201:\n",
    "\n",
    "            if 'content-length' in response.headers and int(response.headers['content-length']) == 0: \n",
    "                result = None \n",
    "            elif 'content-type' in response.headers and isinstance(response.headers['content-type'], str): \n",
    "                if 'application/json' in response.headers['content-type'].lower(): \n",
    "                    result = response.json() if response.content else None \n",
    "                elif 'image' in response.headers['content-type'].lower(): \n",
    "                    result = response.content\n",
    "        else:\n",
    "            print( \"Error code: %d\" % ( response.status_code ) )\n",
    "            print( \"Message: %s\" % ( response.json() ) )\n",
    "\n",
    "        break\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renderResultOnImage( result, img ):\n",
    "    \n",
    "    \"\"\"Display the obtained results onto the input image\"\"\"\n",
    "\n",
    "    R = int(result['color']['accentColor'][:2],16)\n",
    "    G = int(result['color']['accentColor'][2:4],16)\n",
    "    B = int(result['color']['accentColor'][4:],16)\n",
    "\n",
    "    cv2.rectangle( img,(0,0), (img.shape[1], img.shape[0]), color = (R,G,B), thickness = 25 )\n",
    "\n",
    "    if 'categories' in result:\n",
    "        categoryName = sorted(result['categories'], key=lambda x: x['score'])[0]['name']\n",
    "        cv2.putText( img, categoryName, (30,70), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,0,0), 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categories': [{'name': 'trans_trainstation', 'score': 0.98828125}],\n",
       " 'adult': {'isAdultContent': False,\n",
       "  'isRacyContent': False,\n",
       "  'adultScore': 0.010113834403455257,\n",
       "  'racyScore': 0.01534464955329895},\n",
       " 'color': {'dominantColorForeground': 'Black',\n",
       "  'dominantColorBackground': 'Black',\n",
       "  'dominantColors': ['Black'],\n",
       "  'accentColor': '484B83',\n",
       "  'isBwImg': False},\n",
       " 'imageType': {'clipArtType': 0, 'lineDrawingType': 0},\n",
       " 'tags': [{'name': 'platform', 'confidence': 0.967588484287262},\n",
       "  {'name': 'station', 'confidence': 0.8549895882606506},\n",
       "  {'name': 'subway', 'confidence': 0.43907201290130615},\n",
       "  {'name': 'train', 'confidence': 0.1053548734671908}],\n",
       " 'description': {'tags': ['train',\n",
       "   'platform',\n",
       "   'building',\n",
       "   'station',\n",
       "   'track',\n",
       "   'walking',\n",
       "   'subway',\n",
       "   'board',\n",
       "   'pulling',\n",
       "   'holding',\n",
       "   'people',\n",
       "   'man',\n",
       "   'standing',\n",
       "   'waiting',\n",
       "   'luggage',\n",
       "   'woman',\n",
       "   'umbrella'],\n",
       "  'captions': [{'text': 'a person waiting for a train at a train station',\n",
       "    'confidence': 0.6548415158314156}]},\n",
       " 'faces': [],\n",
       " 'requestId': 'e110570c-8767-43a4-ab69-7a306a594b41',\n",
       " 'metadata': {'width': 1500, 'height': 1155, 'format': 'Jpeg'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL direction to image\n",
    "urlImage = 'https://oxfordportal.blob.core.windows.net/vision/Analysis/3.jpg'\n",
    "\n",
    "# Computer Vision parameters\n",
    "params = { 'visualFeatures' : 'Color,Categories,Tags,Description,Faces,ImageType,Adult', 'details': 'Celebrities','Landmarks'} \n",
    "\n",
    "headers = dict()\n",
    "headers['Ocp-Apim-Subscription-Key'] = _key\n",
    "headers['Content-Type'] = 'application/json' \n",
    "\n",
    "json = { 'url': urlImage } \n",
    "data = None\n",
    "\n",
    "result = processRequest( json, data, headers, params )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if result is not None:\n",
    "#     # Load the original image, fetched from the URL\n",
    "#     arr = np.asarray( bytearray( requests.get( urlImage ).content ), dtype=np.uint8 )\n",
    "#     img = cv2.cvtColor( cv2.imdecode( arr, -1 ), cv2.COLOR_BGR2RGB )\n",
    "\n",
    "#     renderResultOnImage( result, img )\n",
    "\n",
    "#     ig, ax = plt.subplots(figsize=(15, 20))\n",
    "#     ax.imshow( img )\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tags': [{'name': 'platform', 'confidence': 0.967588484287262},\n",
       "  {'name': 'station', 'confidence': 0.8549895882606506},\n",
       "  {'name': 'subway', 'confidence': 0.43907201290130615},\n",
       "  {'name': 'train', 'confidence': 0.1053548734671908}],\n",
       " 'requestId': 'd0ba2864-cfb8-4468-be35-d834c0444e0d',\n",
       " 'metadata': {'width': 1500, 'height': 1155, 'format': 'Jpeg'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\tmp\\\\3.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b86024b76e0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Load raw image file into memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpathToFileInDisk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'D:\\tmp\\3.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpathToFileInDisk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\tmp\\\\3.jpg'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load raw image file into memory\n",
    "pathToFileInDisk = r'D:\\tmp\\3.jpg'\n",
    "with open( pathToFileInDisk, 'rb' ) as f:\n",
    "    data = f.read()\n",
    "    \n",
    "# Computer Vision parameters\n",
    "params = { 'visualFeatures' : 'Color,Categories'} \n",
    "\n",
    "headers = dict()\n",
    "headers['Ocp-Apim-Subscription-Key'] = _key\n",
    "headers['Content-Type'] = 'application/octet-stream'\n",
    "\n",
    "json = None\n",
    "\n",
    "result = processRequest( json, data, headers, params )\n",
    "\n",
    "if result is not None:\n",
    "    # Load the original image, fetched from the URL\n",
    "    data8uint = np.fromstring( data, np.uint8 ) # Convert string to an unsigned int array\n",
    "    img = cv2.cvtColor( cv2.imdecode( data8uint, cv2.IMREAD_COLOR ), cv2.COLOR_BGR2RGB )\n",
    "\n",
    "    renderResultOnImage( result, img )\n",
    "\n",
    "    ig, ax = plt.subplots(figsize=(15, 20))\n",
    "    ax.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
